---
title: "stacks"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{stacks}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

In this article, we'll be working through an example of the basic workflow of model stacking with the stacks package. If you're unfamiliar with the language used in this vignette, please see the package README. At a high level, the workflow looks something like this:

1. Define candidate ensemble members using functionality from rsample, parsnip, workflows, recipes, and tune
2. Initialize a `data_stack` object with `stacks()`  
3. Iteratively add candidate ensemble members to the `data_stack` with `add_candidates()`  
4. Evaluate how to combine their predictions with `stack_linear()`  
5. Fit candidate ensemble members with non-zero stacking coefficients with `fit_members()`  
6. Predict on new data with `predict()`!  

The package is closely integrated with the rest of the functionality in tidymodels—we'll load those packages as well. 

```{r setup}
library(tidymodels)
library(stacks)
```

In this example, we'll make use of the `palmerpenguins::penguins` data, giving measurements taken from three different species of penguins from three different antarctic islands! We'll start out with predicting bill length based on other attributes.

```{r}
library(palmerpenguins)
data("penguins")

str(penguins)

penguins <- penguins[!is.na(penguins$sex),]
```

# Define candidate ensemble members

Defining the constituent model definitions is undoubtedly the longest part of building an ensemble with `stacks`. If you're familiar with tidymodels "proper," you're probably fine to skip this section, keeping a few things in mind:

* You'll need to save the assessment set predictions and workflow utilized in your `tune_grid()`, `tune_bayes()`, or `fit_resamples()` objects by setting the `control` arguments  `save_pred = TRUE` and `save_workflow = TRUE`. Note the use of the `control_stack_*()` convenience functions below!
* Each model definition must share the same rsample `rset` object.

We'll first start out with splitting up the training data, generating resamples, and setting some options that will be used by each model definition.

```{r}
# some setup: resampling and a basic recipe
set.seed(1)

penguins_split <- initial_split(penguins)
penguins_train <- training(penguins_split)
penguins_test  <- testing(penguins_split)

folds <- rsample::vfold_cv(penguins_train, v = 3)

penguins_rec <- 
  recipe(body_mass_g ~ ., data = penguins_train) %>%
  step_dummy(all_nominal()) %>%
  step_zv(all_predictors())

penguins_wflow <- 
  workflow() %>% 
  add_recipe(penguins_rec)

metric <- metric_set(rmse)
```

Tuning and fitting results for use in ensembles need to be fitted with the control arguments `save_pred = TRUE` and `save_workflow = TRUE`—these settings ensure that the assessment set predictions, as well as the workflow used to fit the resamples, are stored in the resulting object. For convenience, stacks supplies some `control_stack_*()` functions to generate the appropriate objects for you. 

In this example, we'll be working with `tune_grid()` and `fit_resamples()` from the tune package, so we will use the following control settings:

```{r}
ctrl_grid <- control_stack_grid()
ctrl_res <- control_stack_resamples()
```

We'll fit three different models to try to predict bill length—a linear model, a spline model (with hyperparameters to tune), and a support vector machine model (again, with hyperparameters to tune).

Starting out with linear regression:

```{r}
# create a linear model definition
lin_reg_spec <-
  linear_reg() %>%
  set_engine("lm")

lin_reg_wflow <- 
  penguins_wflow %>% 
  add_model(lin_reg_spec)

lin_reg_res <- 
  fit_resamples(
    lin_reg_wflow,
    resamples = folds,
    metrics = metric,
    control = ctrl_res
  )
```

Since this model definition only has one sub-model, we use `fit_resamples()` rather than `tune_grid()`.

Now, moving on to the spline model:

```{r}
# modify the recipe and use the same linear reg spec
spline_rec <- 
  penguins_rec %>%
  step_ns(bill_length_mm, deg_free = tune::tune("length")) %>%
  step_ns(bill_depth_mm, deg_free = tune::tune("depth"))

spline_wflow <- 
  workflow() %>% 
  add_recipe(spline_rec) %>% 
  add_model(lin_reg_spec)

spline_res <- 
  tune_grid(
    spline_wflow,
    resamples = folds,
    metrics = metric,
    control = ctrl_grid
  )
```

Finally, putting together the model definition for the support vector machine:

```{r}
svm_spec <- 
  svm_rbf(
    cost = tune(), 
    rbf_sigma = tune()
  ) %>%
  set_engine("kernlab") %>%
  set_mode("regression")

svm_wflow <- 
  penguins_wflow %>% 
  add_model(svm_spec)
  
svm_res <- 
  tune_grid(
    svm_wflow, 
    resamples = folds, 
    grid = 5,
    control = ctrl_grid
  )
```

With these three model definitions fully specified, we're ready to start putting together an ensemble!

# Putting together a stack

The first step to building an ensemble with stacks is to create a `data_stack` object—in this package, data stacks are tibbles (with some extra attributes) that contain the assessment set predictions for each candidate ensemble member.

```{r}
stacks()
```

The `stacks()` function works sort of like the `ggplot()` constructor from ggplot2—the function creates a basic structure that the object will be built on top of—except you'll pipe the outputs rather than adding them with `+`.

The `add_candidates()` function adds ensemble members to the stack.

```{r}
penguins_data_st <- 
  stacks() %>%
  add_candidates(lin_reg_res) %>%
  add_candidates(spline_res) %>%
  add_candidates(svm_res)

penguins_data_st
```

As mentioned before, under the hood, a `data_stack` object is really just a tibble. Checking out the actual data:

```{r}
as_tibble(penguins_data_st)
```

A stack is a just a tibble, where the first row gives the first response value, and the remaining columns give the assessment set predictions for each ensemble member. Since we're in the regression case, there's only one column per ensemble member. In classification settings, there are as many columns as there are levels of the outcome variable per candidate ensemble member.

That's it! We're now ready to evaluate how it is that we need to combine predictions from each candidate ensemble member.

# Fit the stack

The outputs from each of these candidate ensemble members are highly correlated, so the `stack_linear` method performs regularization to figure out how we can combine the outputs from the stack members to come up with a final prediction.

```{r, eval = FALSE}
penguins_model_st <-
  penguins_data_st %>%
  stack_linear()
```

The `stack_linear` function determines how member model output will ultimately be combined in the final prediction. Now that we know how to combine our model output, we can fit the models that we now know we need.

```{r, eval = FALSE}
penguins_model_st <-
  penguins_model_st %>%
  fit_members()
```

This object is now ready to predict with new data!
